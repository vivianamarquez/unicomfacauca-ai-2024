{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Cargar librerias"
      ],
      "metadata": {
        "id": "_HQIrsWs2ePU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch # isntalar pytorch usando https://pytorch.org/\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "t5Sr4kdA2dr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configurar el dispositivo\n",
        "\n",
        "Debe determinar si hay una GPU disponible y configurar su dispositivo en consecuencia."
      ],
      "metadata": {
        "id": "2rDp6iki3Kjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Code for MPS (Apple's Metal Performance Shaders)\n",
        "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "# print(f\"Using {device} device\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkwgOVTX3IGc",
        "outputId": "b3bb8001-2854-45e3-9b5d-6a24552ed7c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cargar los datos de Iris"
      ],
      "metadata": {
        "id": "S6Gk5hSc3Ewq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGXdz8g_1zXE"
      },
      "outputs": [],
      "source": [
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dividir el conjunto de datos en un conjunto de entrenamiento y un conjunto de prueba\n"
      ],
      "metadata": {
        "id": "1xhuKVD63Q5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "HD4n64bX3NCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convertir conjuntos de datos en tensores PyTorch\n",
        "\n",
        "En PyTorch, el método .to(device) se utiliza para mover explícitamente tensores o modelos a un dispositivo específico, ya sea la CPU o una GPU. Cuando se entrenan redes neuronales, especialmente las profundas, los requerimientos computacionales pueden ser altos, y utilizar una GPU puede acelerar significativamente el proceso de entrenamiento."
      ],
      "metadata": {
        "id": "Z5kwalZq3u4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.FloatTensor(X_train).to(device)\n",
        "y_train = torch.LongTensor(y_train).to(device)\n",
        "X_test = torch.FloatTensor(X_test).to(device)\n",
        "y_test = torch.LongTensor(y_test).to(device)\n"
      ],
      "metadata": {
        "id": "nKZ6ktZq3T8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definir la estructura de la red neuronal\n",
        "\n",
        "Crear una clase es una forma recomendada de definir modelos en PyTorch. La estructura basada en clases permite un código organizado, modular y escalable. Se pueden crear modelos más sencillos utilizando sólo funciones, pero el uso de clases proporciona una mayor flexibilidad, especialmente para arquitecturas complejas.\n",
        "\n",
        "### Notas:\n",
        "- 12 y 8 son números un tanto arbitrarios. En la práctica, la elección del número de neuronas y capas a menudo implica experimentación.\n",
        "- `nn.Linear` denota capas totalmente conectadas, donde cada neurona de la capa anterior se conecta a cada neurona de la capa actual.\n",
        "- ReLU (Rectified Linear Unit) es una opción popular para las capas ocultas debido a su simplicidad y eficacia.\n",
        "- La última capa no suele utilizar una función de activación porque la elección de la función de pérdida en el paso siguiente (criterio) a veces la incluye.\n",
        "  - Para tareas de clasificación con múltiples clases, `CrossEntropyLoss` en PyTorch combina una activación SoftMax con una pérdida de entropía cruzada.\n"
      ],
      "metadata": {
        "id": "D1Ma89CW4SXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IrisNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(IrisNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 12)    # Primera capa oculta con 12 neuronas\n",
        "        self.fc2 = nn.Linear(12, 8)   # Segunda capa oculta con 8 neuronas\n",
        "        self.fc3 = nn.Linear(8, 3)    # Capa de salida con 3 neuronas (para las 3 clases)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))  # Aplicar la función de activación ReLU después de la primera capa oculta\n",
        "        x = torch.relu(self.fc2(x))  # Aplicar la función de activación ReLU después de la segunda capa oculta\n",
        "        x = self.fc3(x)              # No hay activación aquí ya que usaremos CrossEntropyLoss\n",
        "        return x"
      ],
      "metadata": {
        "id": "kVExpgEK31F0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = IrisNet().to(device)"
      ],
      "metadata": {
        "id": "5wvt4CPj4VaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definir la función de pérdida (error) y el optimizador"
      ],
      "metadata": {
        "id": "CdP7pvT84c1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()               # This combines a SoftMax activation and a cross-entropy loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01) # Adam optimizer with learning rate of 0.01"
      ],
      "metadata": {
        "id": "HXKiKuxr4Zyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bucle de entrenamiento"
      ],
      "metadata": {
        "id": "_fSKbFPn4iPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss = float('inf')  # Comenzar con una pérdida inicial muy alta\n",
        "patience = 10  # Definir cuántas épocas esperar sin mejora\n",
        "counter = 0  # Inicializar el contador\n",
        "\n",
        "for epoch in range(500):   # Aumentar las épocas para asegurar la convergencia con datos sin procesar\n",
        "    optimizer.zero_grad()  # Limpiar los gradientes del último paso\n",
        "    out = model(X_train)   # Paso hacia adelante: calcular la y predicha pasando x al modelo\n",
        "    loss = criterion(out, y_train) # Calcular la pérdida\n",
        "    loss.backward()        # Paso hacia atrás: calcular el gradiente de la pérdida con respecto a los parámetros del modelo\n",
        "    optimizer.step()       # Actualizar los parámetros del modelo\n",
        "\n",
        "    # Evaluar el rendimiento del modelo en los datos de validación\n",
        "    # Asegurarse de que no se calculen gradientes durante este paso para ahorrar computación y memoria\n",
        "    with torch.no_grad():\n",
        "        val_out = model(X_test) # Pasar los datos de validación por el modelo para obtener predicciones\n",
        "        val_loss = criterion(val_out, y_test) # Calcular la pérdida de validación basada en las predicciones del modelo y las etiquetas reales de los datos de validación\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        counter = 0  # Reiniciar el contador ya que hemos observado una mejora en la pérdida de validación\n",
        "    else:\n",
        "        counter += 1  # Si la pérdida de validación no mejora, incrementar el contador\n",
        "\n",
        "    # Si el número de épocas sin mejora excede nuestra paciencia establecida, detener el entrenamiento\n",
        "    if counter >= patience:\n",
        "        print(\"Detención temprana debido a falta de mejora!\")\n",
        "        break  # Salir del bucle de entrenamiento\n",
        "\n",
        "    if (epoch+1) % 50 == 0:  # Imprimir la pérdida cada 50 épocas\n",
        "        print(f\"Época {epoch+1}, Pérdida: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfdz4ZJV4fd6",
        "outputId": "c892c84c-85d5-4da4-c32e-182d14f62e6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50, Loss: 0.7173503637313843\n",
            "Epoch 100, Loss: 0.5290992856025696\n",
            "Epoch 150, Loss: 0.4140053987503052\n",
            "Epoch 200, Loss: 0.34220272302627563\n",
            "Epoch 250, Loss: 0.2906952500343323\n",
            "Epoch 300, Loss: 0.2525676190853119\n",
            "Epoch 350, Loss: 0.22402741014957428\n",
            "Epoch 400, Loss: 0.20210480690002441\n",
            "Epoch 450, Loss: 0.18465901911258698\n",
            "Epoch 500, Loss: 0.17038440704345703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluar el modelo"
      ],
      "metadata": {
        "id": "ABu40qRv4lNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad(): # Desactivar el cálculo de gradientes durante la evaluación para ahorrar memoria y acelerar el proceso\n",
        "    test_out = model(X_test)  # Paso hacia adelante: calcular las salidas predichas pasando los datos de prueba al modelo\n",
        "    _, predicted = torch.max(test_out, 1) # Obtener las etiquetas de clase con las probabilidades predichas más altas\n",
        "    accuracy = accuracy_score(y_test.cpu().numpy(), predicted.cpu().numpy()) # Calcular la precisión comparando las etiquetas predichas con las etiquetas verdaderas\n",
        "    print(f\"Precisión en prueba: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oj-EKXJc4kKw",
        "outputId": "a9ca830b-3d8f-4c6b-aa17-d88e47fe4894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Despliegue\n",
        "Para desplegar un modelo PyTorch\n"
      ],
      "metadata": {
        "id": "C8K_BuxV6EFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el modelo\n",
        "torch.save(model.state_dict(), \"iris_model.pth\")"
      ],
      "metadata": {
        "id": "GmbkqkR94p0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el modelo para inferencia\n",
        "model = IrisNet().to(device)\n",
        "model.load_state_dict(torch.load(\"iris_model.pth\"))\n",
        "model.eval()  # Configurar el modelo en modo de evaluación"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUCZMK6N6IKz",
        "outputId": "5fab5ed4-a8f9-42f7-c309-f689ec663718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IrisNet(\n",
              "  (fc1): Linear(in_features=4, out_features=12, bias=True)\n",
              "  (fc2): Linear(in_features=12, out_features=8, bias=True)\n",
              "  (fc3): Linear(in_features=8, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hacer una predicción con datos nuevos\n",
        "\n",
        "# Supongamos que tienes nuevos datos para predicción en forma de un array de numpy\n",
        "new_data = [[5.1, 3.5, 1.4, 0.2],  # Algunas medidas de iris\n",
        "            [6.7, 3.0, 5.2, 2.3]]  # Otro conjunto de medidas de iris\n",
        "\n",
        "# Convertir los datos a un tensor de PyTorch\n",
        "input_tensor = torch.FloatTensor(new_data)\n",
        "\n",
        "# Si usaste una GPU durante el entrenamiento, mueve el tensor de entrada al mismo dispositivo\n",
        "if torch.cuda.is_available():\n",
        "    input_tensor = input_tensor.to('cuda')\n",
        "\n",
        "# Obtener las predicciones del modelo\n",
        "with torch.no_grad():  # Esto asegura que la operación no sea seguida por autograd de PyTorch\n",
        "    outputs = model(input_tensor)\n",
        "\n",
        "# Obtener las clases predichas\n",
        "_, predicted_classes = torch.max(outputs, 1)\n",
        "\n",
        "# Convertir las clases predichas a una lista\n",
        "predicted_classes = predicted_classes.tolist()\n",
        "\n",
        "print(predicted_classes)  # Esto te dará los índices de las clases predichas para cada entrada"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7py85k_6M2S",
        "outputId": "a7174685-eb36-47b1-b364-a5e7925c92d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Más\n",
        "\n",
        "Otras cosas que deberían ser parte de un modelo de aprendizaje profundo\n",
        "\n",
        "- Ajust de hiperparámetros\n",
        "- Tasa de aprendizaje\n",
        "- Tamaño de lote\n",
        "- Épocas\n",
        "- Optimizador\n",
        "- Arquitectura de red\n",
        "- Abandono\n",
        "- Regularización\n",
        "- Momento\n"
      ],
      "metadata": {
        "id": "xCGZqwd69y1V"
      }
    }
  ]
}