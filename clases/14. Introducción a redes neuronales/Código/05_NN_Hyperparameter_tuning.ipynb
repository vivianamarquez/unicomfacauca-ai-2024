{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load libraries"
      ],
      "metadata": {
        "id": "Ftk5tIju52yl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ji24ilU1FElS",
        "outputId": "65ff7088-41c6-4594-e2ad-311e8c4227ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.4.0-py3-none-any.whl (409 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.6/409.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.12.1-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.8/226.8 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.23)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.0 alembic-1.12.1 colorlog-6.7.0 optuna-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NCw8PZZ5w7O"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import optuna\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set the Device\n",
        "\n",
        "You should determine if a GPU is available and set your device accordingly."
      ],
      "metadata": {
        "id": "HpuclEJr6U2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rr597LnA6MiN",
        "outputId": "27ac54f4-2712-41c4-fdc2-8281cdc31db8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the CIFAR-10 dataset\n",
        "\n",
        "As part of the image preprocessing pipeline for a neural network, we need to prepare the images for input into the model. We use these transformations to ensure that the input images are in the correct format, size, and value range for the neural network to process effectively.\n",
        "\n",
        "In this specific case:\n",
        "\n",
        "1. `transforms.Resize(224)`: Resize the input images to a size of 224x224 pixels. Many pre-trained models, like the ResNet architecture used in this example, are originally trained on the ImageNet dataset, where the standard image size is 224x224.\n",
        "\n",
        "2. `transforms.ToTensor()`: Convert the input images from PIL format or NumPy arrays to PyTorch tensors.\n",
        "\n",
        "3. `transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))`: Normalize the pixel values of the images. In this case, the mean and standard deviation for each channel (Red, Green, Blue) are both set to 0.5. The purpose of normalization is to scale the pixel values to a range that helps with the convergence during training. Normalizing the data typically makes training more efficient and leads to faster convergence."
      ],
      "metadata": {
        "id": "Fu3kf1zi6ZL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(224),  # Resize the images to 224x224\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "train_set = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_set, batch_size=64, shuffle=True, num_workers=2)\n",
        "\n",
        "test_set = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = DataLoader(test_set, batch_size=64, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjD3YLFy6XDf",
        "outputId": "251247e8-86f8-48a1-8f2c-4ef4e38eac9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 12901852.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the Neural Network Architecture with Transfer Learning\n",
        "We'll use a pre-trained ResNet model and modify it for CIFAR-10"
      ],
      "metadata": {
        "id": "91rgSkmc7dw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(dropout_rate):\n",
        "    model = models.resnet18(pretrained=True)\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Dropout(dropout_rate),\n",
        "        nn.Linear(num_ftrs, 10) # CIFAR-10 has 10 classes\n",
        "    )\n",
        "    return model.to(device)"
      ],
      "metadata": {
        "id": "l_z8E30K60Ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define useful functions"
      ],
      "metadata": {
        "id": "hvx-3aQATDKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, optimizer, criterion):\n",
        "    # Sets the model in training mode.\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    # Iterates over training data.\n",
        "    for data, target in train_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()  # Resets gradients to zero before starting backpropagation.\n",
        "        output = model(data)  # Forward pass\n",
        "        loss = criterion(output, target)  # Calculate loss\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update model parameters\n",
        "        total_loss += loss.item()  # Sum up the loss\n",
        "    return total_loss / len(train_loader)  # Return average loss"
      ],
      "metadata": {
        "id": "naiz2xB5TE4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_model(model, test_loader, criterion):\n",
        "    # Sets the model in evaluation mode.\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    # Disables gradient calculations for validations.\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(test_loader)  # Return average validation loss"
      ],
      "metadata": {
        "id": "gmZ30mk_TF0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up Hyperparameter Grid with Optuna\n",
        "\n",
        "How to pick the values for hyperparameters?\n",
        "\n",
        "1. Learning rates\n",
        "  - Common values range between 0.1 and 0.0001.\n",
        "  - Starting with values like 0.001 or 0.01 is common practice. These values are often a good starting point as they are not too large to cause divergence nor too small to slow down convergence significantly.\n",
        "  - You might choose a range of values that decrease by an order of magnitude (e.g., 0.1, 0.01, 0.001) to explore how sensitive your model is to the learning rate.\n",
        "\n",
        "2. Dropout rates\n",
        "  - Typical values range from 0.1 to 0.5.\n",
        "  - Starting with a moderate value like 0.2 or 0.3 can help gauge the effect of dropout on your specific model and dataset.\n",
        "\n",
        "3. Weight Decays (L2 Regularization):\n",
        "  - Common values are small, such as 0.0001, 0.001, or even 0.01, since the regularization term is added to the loss and can significantly influence the gradients if too large."
      ],
      "metadata": {
        "id": "sLuN10rq7pyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    # Suggest hyperparameters\n",
        "    learning_rate = trial.suggest_float(\"lr\", 0.001, 0.01)\n",
        "    dropout_rate = trial.suggest_categorical(\"dropout_rate\", [0.2])\n",
        "    weight_decay = trial.suggest_categorical(\"weight_decay\", [0.0001, 0.001])\n",
        "\n",
        "    print(f\"\\nStarting Trial {trial.number}: lr={learning_rate}, dropout={dropout_rate}, weight_decay={weight_decay}\")\n",
        "\n",
        "    model = create_model(dropout_rate)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training and validation loop\n",
        "    for epoch in range(3):  # Number of epochs can be adjusted\n",
        "        train_loss = train_model(model, train_loader, optimizer, criterion)\n",
        "        val_loss = validate_model(model, test_loader, criterion)\n",
        "        print(f\"Epoch {epoch}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "    # Save the model for this trial\n",
        "    model_path = f\"model_trial_{trial.number}.pth\"\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print(f\"Model saved as {model_path}\")\n",
        "\n",
        "    return val_loss"
      ],
      "metadata": {
        "id": "PIgZE7azTH8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This function trains the model and employs early stopping if the validation loss does not improve.\n",
        "def train_and_evaluate_with_early_stopping(model, train_loader, test_loader, optimizer, criterion, epochs=5):\n",
        "    best_val_loss = float('inf')\n",
        "    early_stopping_patience = 5\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_loss = train_model(model, train_loader, optimizer, criterion)  # Training\n",
        "        val_loss = validate_model(model, test_loader, criterion)  # Validation\n",
        "\n",
        "        # Print loss for every epoch\n",
        "        print(f\"Epoch {epoch}, Train Loss: {train_loss}, Validation Loss: {val_loss}\")\n",
        "\n",
        "        # Check if validation loss improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), \"best_model.pth\")  # Save best model\n",
        "        else:\n",
        "            patience_counter += 1  # Increment patience counter\n",
        "\n",
        "        # Check for early stopping\n",
        "        if patience_counter >= early_stopping_patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    # Load the best model\n",
        "    model.load_state_dict(torch.load(\"best_model.pth\"))"
      ],
      "metadata": {
        "id": "jWMgM4WgTQjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pUBFgwNTSPK",
        "outputId": "b4291515-998d-40db-9b4b-1d3765079a74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-11-22 14:29:10,184] A new study created in memory with name: no-name-23c879e8-6f53-4f19-9b08-9fbaa0c533be\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Trial 0: lr=0.003994808316121756, dropout=0.2, weight_decay=0.001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 172MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Train Loss: 1.4975, Val Loss: 1.9459\n",
            "Epoch 1: Train Loss: 1.1574, Val Loss: 1.4262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-11-22 14:38:27,212] Trial 0 finished with value: 1.0398335984558056 and parameters: {'lr': 0.003994808316121756, 'dropout_rate': 0.2, 'weight_decay': 0.001}. Best is trial 0 with value: 1.0398335984558056.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Loss: 0.9979, Val Loss: 1.0398\n",
            "Model saved as model_trial_0.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Identify Best Configuration and Load the Best Model\n",
        "After hyperparameter tuning with Optuna, load the best performing model."
      ],
      "metadata": {
        "id": "ixNJ4FYbUtLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_trial = study.best_trial\n",
        "print(f\"Best trial: {best_trial.number}\")\n",
        "\n",
        "model = create_model(best_trial.params['dropout_rate'])\n",
        "model.load_state_dict(torch.load(f\"model_trial_{best_trial.number}.pth\"))\n",
        "\n",
        "# Optionally, you can train the model with the best hyperparameters for more epochs\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=best_trial.params['lr'], weight_decay=best_trial.params['weight_decay'])\n",
        "train_and_evaluate_with_early_stopping(model, train_loader, test_loader, optimizer, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cl4z2eDCUux3",
        "outputId": "a555ddad-7187-482b-9324-3d54116e7297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: 0\n",
            "Epoch 0, Train Loss: 0.893689848006229, Validation Loss: 1.0500298746072563\n",
            "Epoch 1, Train Loss: 0.8427119655224978, Validation Loss: 1.3185259916220502\n",
            "Epoch 2, Train Loss: 0.8113234102954645, Validation Loss: 1.161614367157031\n",
            "Epoch 3, Train Loss: 0.7962137435555763, Validation Loss: 1.016058033818652\n",
            "Epoch 4, Train Loss: 0.7717666113391861, Validation Loss: 0.8164087351720044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute Classification Performance Metrics"
      ],
      "metadata": {
        "id": "R1Ghc4FXUzwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_performance(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, targets in test_loader:\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "            outputs = model(data)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy of the model on test images: {accuracy}%')\n",
        "\n",
        "evaluate_performance(model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTHlOxmwU1kc",
        "outputId": "5d5ad560-2ac4-46ea-b611-62265c6cc33c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on test images: 71.44%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Next you could...\n",
        "\n",
        "- Save the model for deployment, load it to make prediction on new data... this could be part of a webapp, etc.\n",
        "- Use GradCAM to understand what the model is using to make predictions\n",
        "- Do Feature Visualization to understand what each layer is \"seeing\""
      ],
      "metadata": {
        "id": "DvX4v9gcU6Cr"
      }
    }
  ]
}